---
layout: post
title: "[DRAFT] TPSAug22"
---

This post tells the journey of a Kaggle competition.
I will describe the experiments ran, the concepts learned, and the results
achieved in August 2022's Tabular Playground Series.

I have three objectives for this document, two of which are severely selfish
while the third is acutely altruistic.
First, I crystallyze my knowledge through writing so this blog post will help
me retain the concepts learned during this competition.
Second, by using a writing-first approach, I hope to bring some kind of order to
my usual chaos-driven experimentation approach.
Finally, I hope to provide to the readers a realistic perspective on how Kaggle
competitions feel and how to succeed in one.


# EDA

I structure my EDA in the following way:

-   Target column
    -   Marginal distribution

        Here you discover if your dataset is imbalanced towards certain
        classes, in the case of classification.
        This is where you would decide to use stratification in the
        cross-validation scheme.
        For regression, you discover the distribution of the target variable
        and start to think about some transformations e.g. log or power
        transform.

    -   Conditional distribution on group

        If your data is clearly divided into various groups, you analyze how the
        target's distribution depends on the group.
        This informs the cross-validation approach, and whether to use a
        GroupKFold or StratifiedGroupKFold

-   Real columns
    -   Conditional distribution on target

        You plot histograms of every real-valued column and check their
        distribution.
        If you are using a linear model or a neural network, here is where you
        think about scaling and/or transformations of the features.

    -   Conditional distribution on group (train and test)

        Plot histograms of every real-valued column and check their
        distribution.
        If there are significant differences in the distribution between groups
        you should think on how to model this, e.g. with a hierarchical model.

    -   Conditional distribution on group, target

    -   Missing conditional distribution on target

    -   Missing conditional distribution on group

    -   Missing conditional distribution on group, target

    -   Meta-features: missing count per row

    <!-- PCA? -->

-   Integer columns
    -   Conditional distribution on target

    -   Conditional distribution on group

    -   Conditional distribution on group, traget

    <!-- No missing values -->

-   Categorical columns
    <!-- The categorical columns define the groups so no group conditional -->

    -   Conditional distribution on target

    <!-- No missing values -->

-   Summary of insights

---

I **should** copy the plotting of failure rate per histogram bins as dots on top
of the histogram.

I **should** try ranking ensemble. Why is roc_auc_score invariant to ranking
when the probabilities get destroyed?

I **need** to try probabilistic programming on this

Plan:
    1.  Implement baseline with statsmodels using only real features, mean
        imputation, standard scaling✅
    2.  Log-transform skewed variables✅
    3.  Add missing features✅
    4.  Add categorical features✅ (didnt work)
    5.  Add integer features✅ (didnt work)
    6.  Add integer features with power transform✅ (didnt work)
    7.  KNN imputation✅
    8.  Impute based on other columns (didnt work. Ohh I need to do it per group)
        -   Even doing it per-group did not seem to improve the CV significantly
    9.  Try sklearn's regularization✅

    Try to reproduce AmbrosM's EDA and then ablate other changes on it

## Workflow ideas

-   EDA
-   Features
    -   Engineering
        -   Select from original df colums you need and copy them, with the index,
            in a new dataframe
        -   Perform the processing you need on this new dataframe
        -   Concat everything at the end
    -   Imputation
        <!-- Predict column using the others? -->
    -   Scaling
    -   Selection
-   Model selection
-   Hyperparameter tuning
-   Adversarial validation

